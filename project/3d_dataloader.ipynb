{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "astropy module not found\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import monai\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "from monai.transforms.utils import allow_missing_keys_mode\n",
    "from monai.transforms import BatchInverseTransform\n",
    "from monai.networks.nets import ResNet\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import medpy.metric as metric\n",
    "import os\n",
    "import dxchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dtu/3d-imaging-center/courses/02510/groups/group_Anhinga/Linea/data_test/image2.nii.gz\n"
     ]
    }
   ],
   "source": [
    "def getBugData(dataset_path: Path):\n",
    "    dataset = []\n",
    "    for idx, item in enumerate(os.listdir(dataset_path)):\n",
    "        one_hot_v = np.zeros(12)\n",
    "        one_hot_v[idx] = 1\n",
    "        if item == \"BC\" or item == \"BF\" or item == \"BL\":\n",
    "            for file in os.listdir(str(dataset_path) + \"/\"+ item):\n",
    "                dataset.append({'image':str(dataset_path) + \"/\"+ item + \"/\" + file,\n",
    "                                 \"class\": str(item),\n",
    "                                 \"label\": one_hot_v})\n",
    "    return dataset\n",
    "\n",
    "DATA_PATH = \"/dtu/3d-imaging-center/courses/02510/data/Bugs/bugnist_128/\"\n",
    "Files = [{\"image\": \"/dtu/3d-imaging-center/courses/02510/groups/group_Anhinga/Linea/data_test/image2.nii.gz\", \"label\": \"test\", \"class\": [0]}]\n",
    "\n",
    "# 1. Data. Make a 70-10-20% train-validation-test split here\n",
    "#Files = getBugData(dataset_path=Path(DATA_PATH))\n",
    "print(Files[0]['image'])\n",
    "\n",
    "#valFiles = getBugData(dataset_path=Path(DATA_PATH))  \n",
    "#testFiles = getBugData(dataset_path=Path(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "#load Files[0]['image']\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import dxchange\n",
    "\n",
    "img = dxchange.read_tiff(Files[0]['image'])\n",
    "print(img.shape)\n",
    "\n",
    "# save as nii\n",
    "nii = nib.Nifti1Image(img, np.eye(4))\n",
    "nib.save(nii, '/dtu/3d-imaging-center/courses/02510/groups/group_Anhinga/Linea/data_test/image2.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImaged(keys='image'),\n",
    "    monai.transforms.EnsureChannelFirstd(keys='image'),\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "train_dataset = Dataset(data=Files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#val_dataset = Dataset(data=valFiles, transform=val_transforms)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "for item in train_loader:\n",
    "    print(item['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(block = 'basic',\n",
    "               layers = [3, 4, 6, 3],\n",
    "                spatial_dims=3, \n",
    "                n_input_channels=1,\n",
    "                num_classes = 3,\n",
    "                block_inplanes = [16, 32, 64, 128],\n",
    ")\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      8\u001b[0m image \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 10\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m()\n\u001b[1;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m model(image)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(output, label)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'long'"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        image = batch['image'].float()\n",
    "    \n",
    "        label = batch['label'].long()\n",
    "        output = model(image)\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(epoch, epoch_loss)\n",
    "    loss.append(epoch_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
